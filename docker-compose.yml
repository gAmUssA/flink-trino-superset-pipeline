services:
  # Kafka - Message broker for data ingestion in KRaft mode
  kafka:
    image: apache/kafka:3.9.0@sha256:fbc7d7c428e3755cf36518d4976596002477e4c052d1f80b5b9eafd06d0fff2f
    hostname: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    healthcheck:
      test: [ "CMD-SHELL", "kafka-topics.sh --bootstrap-server kafka:9092 --list" ]
      interval: 5s
      timeout: 10s
      retries: 10
    environment:
      - PATH=/opt/kafka/bin:$PATH
      # KRaft settings
      - KAFKA_NODE_ID=0
      - KAFKA_PROCESS_ROLES=controller,broker
      - KAFKA_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,PLAINTEXT_HOST://:29092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Additional settings
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_MIN_INSYNC_REPLICAS=1
    networks:
      - pipeline-network
  # Minio - S3-compatible storage for Iceberg data
  minio:
    image: minio/minio:latest@sha256:46b3009bf7041eefbd90bd0d2b38c6ddc24d20a35d609551a1802c558c1c958f
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - pipeline-network

  # Create buckets in Minio
  mc-setup:
    image: minio/mc:latest@sha256:470f5546b596e16c7816b9c3fa7a78ce4076bb73c2c73f7faeec0c8043923123
    container_name: mc-setup
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add myminio http://minio:9000 minioadmin minioadmin) do echo '...waiting for minio...' && sleep 1; done;
      /usr/bin/mc rm -r --force myminio/warehouse || true;
      /usr/bin/mc mb myminio/warehouse;
      /usr/bin/mc policy set public myminio/warehouse;
      exit 0;
      "
    networks:
      - pipeline-network

  # Flink JobManager - Manages Flink jobs
  flink-jobmanager:
    build:
      context: ./flink
      dockerfile: Dockerfile
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        rest.flamegraph.enabled: true
        web.upload.dir: /opt/flink/usrlib
        classloader.resolve-order: parent-first
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - ./flink-jobs:/opt/flink/usrlib
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081/overview" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - pipeline-network

  # Flink TaskManager - Executes Flink tasks
  flink-taskmanager:
    build:
      context: ./flink
      dockerfile: Dockerfile
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        state.backend: filesystem
        state.checkpoints.dir: file:///opt/flink/checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        classloader.resolve-order: parent-first
    volumes:
      - flink-checkpoints:/opt/flink/checkpoints
      - ./flink-jobs:/opt/flink/usrlib
    networks:
      - pipeline-network

  # Iceberg REST Catalog - Metadata service for Iceberg tables
  iceberg-rest:
    image: tabulario/iceberg-rest@sha256:3b7d31bdfec626b68e97531c9778a1b9119659e456fe28545a49f6aa6a9ce472
    container_name: iceberg-rest
    ports:
      - "8181:8181"
    environment:
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
      CATALOG_WAREHOUSE: s3://warehouse
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://192.168.107.4:9000
    networks:
      - pipeline-network
    depends_on:
      - minio

  # Trino Coordinator - SQL query engine
  trino-coordinator:
    image: trinodb/trino:latest@sha256:cc9cab2afd71637176e94c729a05862d1b2d07f5b13b109f1ae041d3e78428dd
    container_name: trino-coordinator
    ports:
      - "8082:8080"
    volumes:
      - ./trino/etc:/etc/trino
    environment:
      - TRINO_USER=admin
      - TRINO_PASSWORD=admin
    networks:
      - pipeline-network
    depends_on:
      - iceberg-rest
      - minio

  # Superset - Data visualization
  superset:
    build:
      context: ./superset
      dockerfile: Dockerfile
    container_name: superset
    ports:
      - "8088:8088"
    environment:
      - ADMIN_USERNAME=admin
      - ADMIN_EMAIL=admin@superset.com
      - ADMIN_PASSWORD=admin
      - SUPERSET_SECRET_KEY="pmFmur1eluMiQDoZA+cGHhY/cA8+0+Ko7EZi5afhXWlH1oH/rQkVHNVOY1hRXAUi"
      - TALISMAN_ENABLED="False"
    volumes:
      - superset-data:/app/superset_home
    networks:
      - pipeline-network

  # Data generator - Produces sample data to Kafka
  data-generator:
    build:
      context: ./data-generator
      dockerfile: Dockerfile
    container_name: data-generator
    depends_on:
      - kafka
    environment:
      # Use 'local' for local development or 'cloud' for Confluent Cloud
      KAFKA_ENV: local
      # These environment variables are used as fallbacks if config files are missing
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_USER_ACTIVITY_TOPIC: user-activity
      KAFKA_SENSOR_DATA_TOPIC: sensor-data
    volumes:
      - ./config:/app/config
    restart: on-failure
    networks:
      - pipeline-network

  # Flink SQL Client - For executing SQL queries on Flink
  flink-sql-client:
    build:
      context: ./flink
      dockerfile: Dockerfile
    container_name: flink-sql-client
    command: bin/sql-client.sh
    depends_on:
      - flink-jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        classloader.resolve-order: parent-first
    volumes:
      - ./flink-jobs:/opt/flink-sql-client/scripts
    networks:
      - pipeline-network
    tty: true
    stdin_open: true

networks:
  pipeline-network:

volumes:
  kafka-data:
  mysql-data:
  minio-data:
  superset-data:
  flink-checkpoints:
